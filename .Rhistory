panel.grid.major = element_line(color = "grey85"),
panel.grid.minor = element_line(color = "grey92"),
axis.line        = element_line(color = "black")
)
out_png <- file.path(out_dir_fig,
paste0("scatter_", janitor::make_clean_names(cname), "_", measure_key, "_ratelog.png"))
ggsave(out_png, p, width = 6.5, height = 6, dpi = 300)
message("✅ Saved plot: ", out_png)
combo_local
}
# ===== Run in a loop for each cause and measure =====
all_combo <- list()
for (cname in cause_map$cause_name) {
all_combo[[length(all_combo)+1]] <- run_one(cname, "prevalence")
# all_combo[[length(all_combo)+1]] <- run_one(cname, "incidence")
}
all_combo_df <- dplyr::bind_rows(all_combo)
readr::write_csv(all_combo_df, out_csv_all)
## version 1 linear model
# # ============================ 依赖 ============================================
# # install.packages(c("tidyverse","janitor","ggrepel","scales"))
# library(tidyverse)
# library(janitor)
# library(ggrepel)
# library(scales)
#
# # ============================ 配置 ============================================
# paths <- list(
#   gbd         = "IHME-GBD_2021_DATA-8529efe8-1.csv",  # 你的 GBD 2021 CSV（替换为实际文件名）
#   populations = "20131219.populations.tsv",           # 官方 1KG 人群解释（TSV）
#   metadata    = "pop_super_metadata.csv",             # 无表头：sample,pop,super_pop,gender
#   bucket_map  = "bucket_map.csv"                      # 可选：两列 pop,bucket
# )
#
# # 新增：PGS & 映射表
# paths$scores_dir <- "scores"                # PGS 分数文件所在文件夹
# paths$map        <- "cause_pgs_map.csv"     # 至少包含 cause_name，建议再含 pgs_id / score_file
#
# # 若 GBD 文件含多年份，可指定某一年（否则自动对各国取年均）
# target_year <- NA_integer_  # 如 2013；不筛年设 NA
#
# # 输出
# out_dir_fig <- "fig_by_cause_measure"
# dir.create(out_dir_fig, showWarnings = FALSE, recursive = TRUE)
# out_csv_all <- "pop_meanPGS_vs_metric_ALLCAUSES.csv"
#
# # ============================ 读取 GBD ========================================
# gbd <- readr::read_csv(paths$gbd, show_col_types = FALSE) %>% clean_names()
#
# # 统一关键列名（自动适配不同导出）
# colmap <- list(
#   measure = intersect(names(gbd), c("measure_name","measure")),
#   age     = intersect(names(gbd), c("age_name","age")),
#   sex     = intersect(names(gbd), c("sex_name","sex")),
#   metric  = intersect(names(gbd), c("metric_name","metric")),
#   loc     = intersect(names(gbd), c("location_name","location")),
#   year    = intersect(names(gbd), c("year")),
#   value   = intersect(names(gbd), c("val","value")),
#   cause   = intersect(names(gbd), c("cause_name","cause"))
# )
# stopifnot(length(colmap$measure)==1, length(colmap$age)==1, length(colmap$sex)==1,
#           length(colmap$metric)==1, length(colmap$loc)==1, length(colmap$year)==1,
#           length(colmap$value)==1)
# if (length(colmap$cause)==0) stop("未在 GBD 表中找到 cause 列（如 cause_name / cause）")
#
# # ============================ 读取 1KG populations & metadata =================
# official_pop <- readr::read_tsv(paths$populations, show_col_types = FALSE) %>%
#   clean_names() %>%
#   rename(
#     pop            = population_code,
#     pop_name       = population_description,
#     super_pop_name = super_population
#   ) %>%
#   mutate(
#     super_pop_official = recode(super_pop_name,
#                                 "African"            = "AFR",
#                                 "Ad Mixed American"  = "AMR",
#                                 "East Asian"         = "EAS",
#                                 "European"           = "EUR",
#                                 "South Asian"        = "SAS",
#                                 .default = NA_character_)
#   ) %>%
#   select(pop, pop_name, super_pop_name, super_pop_official)
#
# metadata <- readr::read_csv(paths$metadata,
#                             col_names = c("sample","pop","super_pop","gender"),
#                             show_col_types = FALSE) %>%
#   distinct()
#
# # ============================ pop -> 国家 映射（与 GBD 对齐） =================
# pop2country <- c(
#   ACB="African Union", ASW="African Union", ESN="Nigeria",
#   GWD="Gambia", LWK="Kenya", MSL="Sierra Leone", YRI="Nigeria",
#   CLM="Colombia", MXL="Mexico", PEL="Peru", PUR="Puerto Rico",
#   CDX="China", CHB="China", CHS="China", JPT="Japan", KHV="Viet Nam",
#   CEU="European Region", FIN="Finland", GBR="United Kingdom",
#   IBS="Spain", TSI="Italy",
#   BEB="Bangladesh", GIH="India", ITU="India",
#   PJL="Pakistan", STU="Sri Lanka"
# )
#
# normalize_country <- function(x){
#   dplyr::recode(x,
#                 "Vietnam"="Viet Nam",
#                 "The Gambia"="Gambia",
#                 "USA"="United States of America",
#                 "United States"="United States of America",
#                 "UK"="United Kingdom",
#                 .default = x)
# }
# missing_pops <- setdiff(unique(metadata$pop), names(pop2country))
# if (length(missing_pops) > 0) {
#   guess_tbl <- official_pop %>%
#     filter(pop %in% missing_pops) %>%
#     mutate(country_guess = str_trim(str_extract(pop_name, "[^,]+$")),
#            country_guess = normalize_country(country_guess)) %>%
#     select(pop, country_guess) %>% drop_na()
#   if (nrow(guess_tbl) > 0) {
#     add_map <- setNames(guess_tbl$country_guess, guess_tbl$pop)
#     pop2country <- c(pop2country, add_map)
#   }
# }
#
# # ============================ 映射表（cause ↔ PGS） ===========================
# # 若映射表不存在，自动从 GBD 提取 cause_name 生成模板
# if (!file.exists(paths$map)) {
#   tibble(cause_name = sort(unique(gbd[[colmap$cause]])),
#          pgs_id = NA_character_, score_file = NA_character_) %>%
#     readr::write_csv(paths$map)
#   stop("已生成模板 `", paths$map, "`；请填写每个 cause 对应的 pgs_id 或 score_file 后重跑。")
# }
#
# cause_map <- readr::read_csv(paths$map, show_col_types = FALSE) %>%
#   clean_names()
# for (nm in c("pgs_id","score_file")) if (!nm %in% names(cause_map)) cause_map[[nm]] <- NA_character_
# cause_map <- cause_map %>%
#   mutate(
#     cause_name = as.character(cause_name),
#     pgs_id     = as.character(tidyr::replace_na(pgs_id, "")),
#     score_file = as.character(tidyr::replace_na(score_file, ""))
#   ) %>%
#   filter(!is.na(cause_name), cause_name != "") %>%
#   distinct()
#
# if (nrow(cause_map) == 0) stop("`", paths$map, "` 为空，请填写后再运行。")
#
# # ============================ 工具函数 ========================================
# # 读取一个 scores 文件：识别除 sample 外的第一列为分数列
# read_one_scores <- function(file) {
#   sr <- readr::read_csv(file, show_col_types = FALSE)
#   score_cols <- setdiff(names(sr), "sample")
#   stopifnot(length(score_cols) >= 1)
#   nm <- score_cols[1]
#   sr %>%
#     select(sample, !!nm) %>%
#     rename(score = !!nm) %>%
#     mutate(score = suppressWarnings(as.numeric(score)))
# }
#
# # 根据 pgs_id 猜测文件名（两种常见命名都尝试）
# guess_score_path <- function(pgs_id, scores_dir) {
#   if (is.na(pgs_id) || pgs_id == "") return(NA_character_)
#   cand <- c(file.path(scores_dir, paste0(pgs_id, "_scores.txt")),
#             file.path(scores_dir, paste0(pgs_id, "scores.txt")))
#   cand[which(file.exists(cand))][1] %||% cand[1]
# }
# `%||%` <- function(x, y) if (is.null(x) || (length(x)==1 && is.na(x)) || (length(x)==1 && x=="")) y else x
#
# # GBD 公共过滤（age/sex/metric & 数值化）
# base_filter <- function(d) {
#   d %>%
#     filter(
#       str_to_lower(!!sym(colmap$age)) == "all ages",
#       str_to_lower(!!sym(colmap$sex)) %in% c("both","both sexes"),
#       str_detect(!!sym(colmap$metric), regex("percent", TRUE))
#     ) %>%
#     mutate(
#       .value = suppressWarnings(as.numeric(!!sym(colmap$value))),
#       .year  = suppressWarnings(as.integer(!!sym(colmap$year)))
#     ) %>%
#     filter(!is.na(.value))
# }
#
# # 颜色盘
# pal <- c(AFR="#B39D00", AMR="#F8766D", EAS="#00BFC4", EUR="#00A9FF", SAS="#F564E3")
#
# # ============================ 单个疾病 × 单个 measure =========================
# run_one <- function(cname, measure_key = c("prevalence","incidence")) {
#   measure_key <- match.arg(measure_key)
#
#   # 1) 找分数文件：优先 score_file，否则根据 pgs_id 猜
#   row <- cause_map %>% filter(str_to_lower(cause_name) == str_to_lower(cname)) %>% slice(1)
#   if (nrow(row) == 0) {
#     message("⚠️ 映射表中没有找到疾病: ", cname)
#     return(tibble())
#   }
#
#   sfile <- row$score_file
#   if (is.na(sfile) || sfile == "") sfile <- guess_score_path(row$pgs_id, paths$scores_dir)
#
#   # 如果文件不存在，给出提醒并跳过
#   if (is.na(sfile) || sfile == "" || !file.exists(sfile)) {
#     message("⚠️ 找不到 PGS 分数文件: ", sfile, " (cause: ", cname, ", pgs_id: ", row$pgs_id, ") — 已跳过")
#     return(tibble())
#   }
#
#   # 2) 读 scores & 合并样本、映射国家
#   scores <- read_one_scores(sfile)
#   df_local <- metadata %>%
#     left_join(official_pop, by="pop") %>%
#     inner_join(scores, by="sample") %>%
#     mutate(country = dplyr::recode(pop, !!!as.list(pop2country))) %>%
#     filter(!is.na(pop), !is.na(super_pop), !is.na(country)) %>%
#     mutate(cause_name = cname,
#            pgs_id = if (is.na(row$pgs_id) || row$pgs_id=="") basename(sfile) else row$pgs_id)
#
#   if (file.exists(paths$bucket_map)) {
#     bucket_map <- readr::read_csv(paths$bucket_map, show_col_types = FALSE) %>%
#       clean_names() %>% select(pop, bucket) %>% mutate(across(everything(), as.character))
#     df_local <- df_local %>% left_join(bucket_map, by="pop") %>%
#       mutate(bucket = if_else(is.na(bucket), pop, bucket))
#   } else {
#     df_local <- df_local %>% mutate(bucket = pop)
#   }
#
#   # 3) GBD 子集
#   gbd_sub <- gbd %>%
#     filter(
#       str_to_lower(!!sym(colmap$cause)) == str_to_lower(cname),
#       str_detect(!!sym(colmap$measure), regex(measure_key, TRUE))
#     ) %>%
#     base_filter()
#   if (!is.na(target_year)) gbd_sub <- gbd_sub %>% filter(.year == target_year)
#
#   gbd_country_local <- gbd_sub %>%
#     group_by(country = !!sym(colmap$loc)) %>%
#     summarise(y_metric = mean(.value, na.rm = TRUE), .groups = "drop")
#
#   # 4) 每个 pop 的 PGS 均值 + GBD 指标
#   pgs_by_pop_local <- df_local %>%
#     group_by(cause_name, pgs_id, pop, super_pop, bucket) %>%
#     summarise(n = n(),
#               mean_pgs = mean(score, na.rm = TRUE),
#               sd_pgs   = sd(score, na.rm = TRUE),
#               .groups  = "drop")
#
#   pop_country_metric_local <- df_local %>%
#     distinct(pop, country) %>%
#     left_join(gbd_country_local, by = "country")
#
#   combo_local <- pgs_by_pop_local %>%
#     left_join(pop_country_metric_local, by = "pop") %>%
#     filter(!is.na(y_metric)) %>%
#     mutate(measure_used = measure_key)
#
#   # 5) 出图
#   if (nrow(combo_local) == 0) {
#     message("⚠️ 数据为空 (cause: ", cname, ", measure: ", measure_key, ") — 跳过绘图")
#     return(tibble())
#   }
#
#   ct <- suppressWarnings(cor.test(combo_local$mean_pgs, combo_local$y_metric, method = "pearson"))
#   r_txt <- sprintf("italic(r) == %.2f", unname(ct$estimate))
#   p_txt <- sprintf("italic(p) == %s",
#                    if (ct$p.value < 1e-4) format(ct$p.value, digits=1, scientific=TRUE)
#                    else sprintf("%.3f", ct$p.value))
#
#   p <- ggplot(combo_local, aes(x = mean_pgs, y = y_metric, color = super_pop, label = bucket)) +
#     geom_point(size = 3) +
#     ggrepel::geom_text_repel(show.legend = FALSE, min.segment.length = 0) +
#     scale_color_manual(values = pal, drop = FALSE) +
#     geom_smooth(method = "lm", se = FALSE, color = "gray40", linetype = "dashed") +
#     annotate("text", x = -Inf, y = Inf, label = r_txt, parse = TRUE,
#              hjust = -0.1, vjust = 1.6, size = 5) +
#     annotate("text", x = -Inf, y = Inf, label = p_txt, parse = TRUE,
#              hjust = -0.1, vjust = 3.0, size = 5) +
#     labs(
#       title = paste0(cname, " | ", str_to_title(measure_key)),
#       x = "PGS (mean by population)",
#       y = paste0(str_to_title(measure_key), " — country average (value)"),
#       color = "super_pop"
#     ) +
#     theme_minimal(base_size = 13) +
#     theme(
#       panel.background = element_rect(fill = "white", color = "black"),   # 白底+黑边框
#       plot.background  = element_rect(fill = "white", color = NA),        # 整个图背景白
#       panel.grid.major = element_line(color = "grey85"),                  # 浅灰色主网格
#       panel.grid.minor = element_line(color = "grey92"),                  # 更浅的次网格
#       axis.line        = element_line(color = "black")                    # 坐标轴黑线
#     )
#
#
#   out_png <- file.path(out_dir_fig,
#                        paste0("scatter_", janitor::make_clean_names(cname), "_", measure_key, ".png"))
#   ggsave(out_png, p, width = 6.5, height = 6, dpi = 300)
#   message("✅ Saved plot: ", out_png)
#
#   combo_local
# }
#
# # ===== 批量运行：每个疾病 × {prevalence, incidence} =====
# all_combo <- list()
# for (cname in cause_map$cause_name) {
#   all_combo[[length(all_combo)+1]] <- run_one(cname, "prevalence")
#   all_combo[[length(all_combo)+1]] <- run_one(cname, "incidence")
# }
# all_combo_df <- dplyr::bind_rows(all_combo)
# readr::write_csv(all_combo_df, out_csv_all)
#
# # ============================ 依赖 ============================================
# # install.packages(c("tidyverse","janitor","ggrepel","scales"))
# library(tidyverse)
# library(janitor)
# library(ggrepel)
# library(scales)
#
# # ============================ 配置 ============================================
# paths <- list(
#   gbd         = "IHME-GBD_2021_DATA-84caca4d-1.csv",  # GBD 2021 导出（CSV）
#   populations = "20131219.populations.tsv",           # 官方 1KG 人群解释（TSV）
#   metadata    = "pop_super_metadata.csv",             # 无表头：sample,pop,super_pop,gender
#   scores      = "PGS005110scores.txt",               # 含 sample 与一个 PGS 列
#   bucket_map  = "bucket_map.csv"                      # 可选：两列 pop,bucket
# )
#
# # 若 GBD 文件含多年份，可指定某一年（否则自动对各国取年均）
# target_year <- NA_integer_  # 如 2013；不筛年则设 NA
#
# # 输出文件
# out_csv  <- "pop_meanPGS_vs_metric.csv"
# out_png  <- "scatter_pop_meanPGS_vs_metric.png"
#
# # ============================ 读取数据 ========================================
# # 1) GBD（自动兼容 prevalence/incidence、Both/Both sexes、Location/val 等列名）
# gbd <- readr::read_csv(paths$gbd, show_col_types = FALSE) %>% clean_names()
#
# # 统一关键列名
# colmap <- list(
#   measure = intersect(names(gbd), c("measure_name","measure")),
#   age     = intersect(names(gbd), c("age_name","age")),
#   sex     = intersect(names(gbd), c("sex_name","sex")),
#   metric  = intersect(names(gbd), c("metric_name","metric")),
#   loc     = intersect(names(gbd), c("location_name","location")),
#   year    = intersect(names(gbd), c("year")),
#   value   = intersect(names(gbd), c("val","value"))
# )
# stopifnot(length(colmap$measure)==1, length(colmap$age)==1, length(colmap$sex)==1,
#           length(colmap$metric)==1, length(colmap$loc)==1, length(colmap$year)==1,
#           length(colmap$value)==1)
#
# # 选择指标：优先 Prevalence；没有则用 Incidence（你的文件多为 Incidence）
# has_prev <- any(str_detect(gbd[[colmap$measure]], regex("prevalence", TRUE)))
# measure_target <- if (has_prev) "prevalence" else "incidence"
#
# gbd_sel <- gbd %>%
#   filter(
#     str_detect(!!sym(colmap$measure), regex(measure_target, TRUE)),
#     str_to_lower(!!sym(colmap$age)) == "all ages",
#     str_to_lower(!!sym(colmap$sex)) %in% c("both", "both sexes"),
#     str_detect(!!sym(colmap$metric), regex("percent", TRUE))
#   ) %>%
#   mutate(
#     .value = suppressWarnings(as.numeric(!!sym(colmap$value))),
#     .year  = suppressWarnings(as.integer(!!sym(colmap$year)))
#   ) %>%
#   filter(!is.na(.value))
#
# if (!is.na(target_year)) {
#   gbd_sel <- gbd_sel %>% filter(.year == target_year)
# }
#
# gbd_country <- gbd_sel %>%
#   group_by(country = !!sym(colmap$loc)) %>%
#   summarise(y_metric = mean(.value, na.rm = TRUE), .groups = "drop")
#
# # 2) 官方 populations.tsv（拿到 pop 描述）
# official_pop <- readr::read_tsv(paths$populations, show_col_types = FALSE) %>%
#   clean_names() %>%
#   rename(
#     pop            = population_code,
#     pop_name       = population_description,
#     super_pop_name = super_population
#   ) %>%
#   mutate(
#     super_pop_official = recode(super_pop_name,
#                                 "African"            = "AFR",
#                                 "Ad Mixed American"  = "AMR",
#                                 "East Asian"         = "EAS",
#                                 "European"           = "EUR",
#                                 "South Asian"        = "SAS",
#                                 .default = NA_character_)
#   ) %>%
#   select(pop, pop_name, super_pop_name, super_pop_official)
#
# # 3) metadata（无表头） + 4) PGS（识别除 sample 外的第一列为 PGS）
# metadata <- readr::read_csv(paths$metadata,
#                             col_names = c("sample","pop","super_pop","gender"),
#                             show_col_types = FALSE) %>%
#   distinct()
#
# scores_raw <- readr::read_csv(paths$scores, show_col_types = FALSE)
# score_cols <- setdiff(names(scores_raw), "sample")
# stopifnot(length(score_cols) >= 1)
# score_name <- score_cols[1]
# scores <- scores_raw %>%
#   select(sample, !!score_name) %>%
#   rename(score = !!score_name) %>%
#   mutate(score = suppressWarnings(as.numeric(score)))
#
# # ============================ pop -> 国家 映射 ===============================
# # 以采样国家为口径（与 GBD 国家对齐）
# pop2country <- c(
#   ACB="African Union", ASW="African Union", ESN="Nigeria",
#   GWD="Gambia", LWK="Kenya", MSL="Sierra Leone", YRI="Nigeria",
#   CLM="Colombia", MXL="Mexico", PEL="Peru", PUR="Puerto Rico",
#   CDX="China", CHB="China", CHS="China", JPT="Japan", KHV="Viet Nam",
#   CEU="European Region", FIN="Finland", GBR="United Kingdom",
#   IBS="Spain", TSI="Italy",
#   BEB="Bangladesh", GIH="India", ITU="India",
#   PJL="Pakistan", STU="Sri Lanka"
# )
#
# # 若有遗漏，尝试从 pop 描述中按最后一个逗号后的地名猜测，并做必要标准化
# normalize_country <- function(x){
#   dplyr::recode(x,
#                 "Vietnam"="Viet Nam",
#                 "The Gambia"="Gambia",
#                 "USA"="United States of America",
#                 "United States"="United States of America",
#                 "UK"="United Kingdom",
#                 .default = x)
# }
# missing_pops <- setdiff(unique(metadata$pop), names(pop2country))
# if (length(missing_pops) > 0) {
#   guess_tbl <- official_pop %>%
#     filter(pop %in% missing_pops) %>%
#     mutate(country_guess = str_trim(str_extract(pop_name, "[^,]+$")),
#            country_guess = normalize_country(country_guess)) %>%
#     select(pop, country_guess) %>% drop_na()
#   if (nrow(guess_tbl) > 0) {
#     add_map <- setNames(guess_tbl$country_guess, guess_tbl$pop)
#     pop2country <- c(pop2country, add_map)
#   }
# }
#
# # ============================ 合并、分组 ======================================
# df <- metadata %>%
#   left_join(official_pop, by="pop") %>%
#   inner_join(scores, by="sample") %>%
#   mutate(country = recode(pop, !!!as.list(pop2country))) %>%
#   filter(!is.na(pop), !is.na(super_pop), !is.na(country))
#
# # 可选：多个 pop 合并为一个 bucket（若有 bucket_map.csv）
# if (file.exists(paths$bucket_map)) {
#   bucket_map <- readr::read_csv(paths$bucket_map, show_col_types = FALSE) %>%
#     clean_names() %>% select(pop, bucket) %>% mutate(across(everything(), as.character))
#   df <- df %>% left_join(bucket_map, by="pop") %>%
#     mutate(bucket = if_else(is.na(bucket), pop, bucket))
# } else {
#   df <- df %>% mutate(bucket = pop) # 默认每个 pop 独立
# }
#
# # 每个 pop（或 bucket）均值 PGS
# pgs_by_pop <- df %>%
#   group_by(pop, super_pop, bucket) %>%
#   summarise(n = n(), mean_pgs = mean(score, na.rm = TRUE),
#             sd_pgs = sd(score, na.rm = TRUE), .groups="drop")
#
# # 合并国家指标（把每个 pop 映射到其国家，再把该国的 GBD 指标拼上）
# pop_country_metric <- df %>%
#   distinct(pop, country) %>%
#   left_join(gbd_country, by = c("country" = "country"))
#
# combo <- pgs_by_pop %>%
#   left_join(pop_country_metric, by = "pop") %>%
#   filter(!is.na(y_metric))
#
# # 保存总表
# readr::write_csv(combo, out_csv)
# message("Saved table: ", out_csv)
#
# # ============================ 散点图（像你截图那样） ==========================
# # 颜色：按 super_pop 固定一个调色盘（近似示意）
# pal <- c(AFR="#B39D00", AMR="#F8766D", EAS="#00BFC4", EUR="#00A9FF", SAS="#F564E3")
#
# # 相关系数（Pearson）
# ct <- suppressWarnings(cor.test(combo$mean_pgs, combo$y_metric, method = "pearson"))
# r_txt <- sprintf("italic(r) == %.2f", unname(ct$estimate))
# p_txt <- sprintf("italic(p) == %s",
#                  if (ct$p.value < 1e-4) format(ct$p.value, digits=1, scientific=TRUE)
#                  else sprintf("%.3f", ct$p.value))
#
# p <- ggplot(combo, aes(x = mean_pgs, y = y_metric, color = super_pop, label = bucket)) +
#   geom_point(size = 3) +
#   ggrepel::geom_text_repel(show.legend = FALSE, min.segment.length = 0) +
#   scale_color_manual(values = pal, drop = FALSE) +
#   geom_smooth(method = "lm", se = FALSE, color = "grey40", linetype = "dashed") +
#   annotate("text", x = -Inf, y = Inf, label = r_txt, parse = TRUE,
#            hjust = -0.1, vjust = 1.6, size = 5) +
#   annotate("text", x = -Inf, y = Inf, label = p_txt, parse = TRUE,
#            hjust = -0.1, vjust = 3.0, size = 5) +
#   labs(
#     x = "PGS (mean by population)",
#     y = sprintf("%s — GBD country average", str_to_title(measure_target)),
#     color = "super_pop"
#   ) +
#   theme_minimal(base_size = 13) +
#   theme(panel.grid.major = element_line(color = "grey88"),
#         panel.grid.minor = element_blank())
#
# ggsave(out_png, p, width = 6.5, height = 6, dpi = 300)
# message("Saved plot: ", out_png)
